# Open Higgsfield AI â€” Open-Source Alternative to Higgsfield AI

> **The free, open-source alternative to Higgsfield AI.** Generate AI images and videos using 200+ state-of-the-art models â€” without the closed ecosystem or subscription fees.

Open Higgsfield AI is an open-source AI image, video, and cinema studio that brings Higgsfield-style creative workflows to everyone. Powered by [Muapi.ai](https://muapi.ai), it supports text-to-image, image-to-image, text-to-video, and image-to-video generation across models like Flux, Nano Banana, Midjourney, Kling, Sora, Veo, Seedream, and more â€” all from a sleek, modern interface you can self-host and customize.

**Why Open Higgsfield AI instead of Higgsfield AI?**
- **Free & open-source** â€” no subscription, no vendor lock-in
- **Self-hosted** â€” your data stays on your machine
- **200+ models** â€” text-to-image, image-to-image, text-to-video, image-to-video
- **Multi-image input** â€” feed up to 14 reference images into compatible models
- **Extensible** â€” add your own models, modify the UI, build on top of it

For a deep dive into the technical architecture and the philosophy behind the "Infinite Budget" cinema workflow, see our [comprehensive guide and roadmap](https://medium.com/@anilmatcha/building-open-higgsfield-ai-an-open-source-ai-cinema-studio-83c1e0a2a5f1).

![Studio Demo](docs/assets/studio_demo.webp)

## âœ¨ Features

- **Image Studio** â€” Generate images from text prompts (50+ text-to-image models) or transform existing images (55+ image-to-image models). Switches model set automatically based on whether a reference image is provided. Quality and resolution controls visible for models that support them.
- **Multi-Image Input** â€” Upload up to 14 reference images for compatible edit models (Nano Banana 2 Edit, Flux Kontext Dev, GPT-4o Edit, and more). Multi-select picker with order badges, batch upload, and a "Use Selected" confirmation flow.
- **Video Studio** â€” Generate videos from text prompts (40+ text-to-video models) or animate a start-frame image (60+ image-to-video models). Same intelligent mode switching as Image Studio.
- **Cinema Studio** â€” Higgsfield AI-style interface for photorealistic cinematic shots with pro camera controls (Lens, Focal Length, Aperture)
- **Upload History** â€” Reference images are uploaded once and stored locally. A picker panel lets you reuse any previously uploaded image across sessions â€” no re-uploading.
- **Smart Controls** â€” Dynamic aspect ratio, resolution/quality, and duration pickers that adapt to each model's capabilities (including t2i models with resolution or quality options)
- **Generation History** â€” Browse, revisit, and download all past generations (persisted in browser storage)
- **Image & Video Download** â€” One-click download of generated outputs in full resolution
- **API Key Management** â€” Secure API key storage in browser localStorage (never sent to any server except Muapi)
- **Responsive Design** â€” Works seamlessly on desktop and mobile with dark glassmorphism UI

### ğŸ–¼ï¸ Image Studio â€” Dual Mode

The Image Studio automatically switches between two model sets:

| Mode | Trigger | Models | Prompt |
| :--- | :--- | :--- | :--- |
| **Text-to-Image** | Default (no image) | 50+ t2i models (Flux, Nano Banana 2, Seedream 5.0, Ideogram, GPT-4o, Midjourneyâ€¦) | Required |
| **Image-to-Image** | Reference image uploaded | 55+ i2i models (Kontext, Nano Banana 2 Edit, Seedream 5.0 Edit, Seededit, Upscalerâ€¦) | Optional |

#### Newly Added Models

| Model | Type | Key Features |
| :--- | :--- | :--- |
| **Nano Banana 2** | Text-to-Image | Google Gemini 3.1 Flash Image Â· Resolution 1K/2K/4K Â· Google Search enhancement Â· aspect ratio `auto` |
| **Nano Banana 2 Edit** | Image-to-Image | Up to **14 reference images** Â· Resolution 1K/2K/4K Â· Google Search enhancement |
| **Seedream 5.0** | Text-to-Image | ByteDance Â· Quality basic/high Â· 8 aspect ratios Â· up to 4K |
| **Seedream 5.0 Edit** | Image-to-Image | ByteDance Â· Natural language style transfer Â· Quality basic/high |

#### Multi-Image Input

Models that accept multiple reference images expose a multi-select picker when active:

| Model | Max Images |
| :--- | :--- |
| Nano Banana 2 Edit | 14 |
| Nano Banana Edit | 10 |
| Flux Kontext Dev I2I | 10 |
| Kling O1 Edit Image | 10 |
| GPT-4o Edit / GPT Image 1.5 Edit | 10 |
| Bytedance Seedream Edit v4 / v4.5 | 10 |
| Vidu Q2 Reference to Image | 7 |
| Flux 2 Flex/Pro Edit | 8 |
| Nano Banana Pro Edit | 8 |
| Flux Kontext Pro/Max I2I | 2 |
| Wan 2.5/2.6 Image Edit | 2â€“3 |
| Qwen Image Edit Plus / 2511 | 3 |
| GPT-4o Image to Image | 5 |
| Flux 2 Klein 4b/9b Edit | 4 |

When a multi-image model is selected the upload trigger switches to multi-select mode:
- **Checkboxes with order numbers** â€” images are sent to the model in the order you select them
- **Batch upload** â€” pick multiple files at once from your file dialog
- **Count badge** on the trigger shows how many images are active; a `+` badge appears when more slots are available
- **"Use Selected" button** confirms and closes the picker

### ğŸ¬ Video Studio â€” Dual Mode

The Video Studio follows the same pattern:

| Mode | Trigger | Models | Prompt |
| :--- | :--- | :--- | :--- |
| **Text-to-Video** | Default (no image) | 40+ t2v models (Kling, Sora, Veo, Wan, Seedance, Hailuo, Runwayâ€¦) | Required |
| **Image-to-Video** | Start frame uploaded | 60+ i2v models (Kling I2V, Veo3 I2V, Runway I2V, Wan I2V, Midjourney I2Vâ€¦) | Optional |

### ğŸ¥ Cinema Studio Controls

The **Cinema Studio** offers precise control over the virtual camera, translating your choices into optimized prompt modifiers:

| Category | Available Options |
| :--- | :--- |
| **Cameras** | Modular 8K Digital, Full-Frame Cine Digital, Grand Format 70mm Film, Studio Digital S35, Classic 16mm Film, Premium Large Format Digital |
| **Lenses** | Creative Tilt, Compact Anamorphic, Extreme Macro, 70s Cinema Prime, Classic Anamorphic, Premium Modern Prime, Warm Cinema Prime, Swirl Bokeh Portrait, Vintage Prime, Halation Diffusion, Clinical Sharp Prime |
| **Focal Lengths** | 8mm (Ultra-Wide), 14mm, 24mm, 35mm (Human Eye), 50mm (Portrait), 85mm (Tight Portrait) |
| **Apertures** | f/1.4 (Shallow DoF), f/4 (Balanced), f/11 (Deep Focus) |

### ğŸ“ Upload History & Picker

Every image you upload is saved locally (URL + thumbnail) so you never upload the same file twice:

- Click the upload button to open the **reference image picker**
- Previously uploaded images appear in a 3-column grid with thumbnails
- **Single-image models** â€” click a thumbnail to instantly select and close
- **Multi-image models** â€” toggle multiple thumbnails (shown with order numbers), then click **Use Selected**
- Upload new images with the **Upload files** button (supports multi-file selection in multi-image mode)
- Remove individual images from history with the âœ• button
- History persists across browser sessions (stored in `localStorage`)

## ğŸš€ Quick Start

### Prerequisites

- [Node.js](https://nodejs.org/) (v18+)
- A [Muapi.ai](https://muapi.ai) API key

### Setup

```bash
# Clone the repository
git clone https://github.com/Anil-matcha/Open-Higgsfield-AI.git
cd Open-Higgsfield-AI

# Install dependencies
npm install

# Start the development server
npm run dev
```

Open `http://localhost:5173` in your browser. You'll be prompted to enter your Muapi API key on first use.

### Production Build

```bash
npm run build
npm run preview
```

## ğŸ—ï¸ Architecture

```
src/
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ ImageStudio.js    # Dual-mode t2i/i2i studio with dynamic model switching & multi-image support
â”‚   â”œâ”€â”€ VideoStudio.js    # Dual-mode t2v/i2v studio with dynamic model switching
â”‚   â”œâ”€â”€ CinemaStudio.js   # Pro studio with camera controls & infinite canvas flow
â”‚   â”œâ”€â”€ UploadPicker.js   # Upload button + history panel; single & multi-image select modes
â”‚   â”œâ”€â”€ CameraControls.js # Scrollable picker for camera/lens/focal/aperture
â”‚   â”œâ”€â”€ Header.js         # App header with settings and controls
â”‚   â”œâ”€â”€ AuthModal.js      # API key input modal
â”‚   â”œâ”€â”€ SettingsModal.js  # Settings panel for API key management
â”‚   â””â”€â”€ Sidebar.js        # Navigation sidebar
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ muapi.js          # API client: generateImage, generateVideo, generateI2I, generateI2V, uploadFile
â”‚   â”œâ”€â”€ models.js         # 200+ model definitions with endpoints, inputs, maxImages, quality/resolution mappings
â”‚   â””â”€â”€ uploadHistory.js  # localStorage CRUD + canvas thumbnail generation for upload history
â”œâ”€â”€ styles/
â”‚   â”œâ”€â”€ global.css        # Global styles and animations
â”‚   â”œâ”€â”€ studio.css        # Studio-specific styles
â”‚   â””â”€â”€ variables.css     # CSS custom properties
â”œâ”€â”€ main.js               # App entry point
â””â”€â”€ style.css             # Tailwind imports
```

## ğŸ”Œ API Integration

The app communicates with [Muapi.ai](https://muapi.ai) using a two-step pattern:

1. **Submit** â€” `POST /api/v1/{model-endpoint}` with prompt and parameters
2. **Poll** â€” `GET /api/v1/predictions/{request_id}/result` until status is `completed`

Authentication uses the `x-api-key` header. During development, a Vite proxy handles CORS by routing `/api` requests to `https://api.muapi.ai`.

File uploads use `POST /api/v1/upload_file` (multipart/form-data) and return a hosted URL that is passed to image-conditioned models. For multi-image models the full `images_list` array is forwarded to the API in one request.

## ğŸ¨ Supported Model Categories

| Category | Count | Examples |
|---|---|---|
| **Text-to-Image** | 50+ | Flux Dev, Nano Banana 2, Seedream 5.0, Ideogram v3, Midjourney v7, GPT-4o, SDXL |
| **Image-to-Image** | 55+ | Nano Banana 2 Edit (Ã—14), Flux Kontext Pro, GPT-4o Edit, Seededit v3, Upscaler, Background Remover |
| **Text-to-Video** | 40+ | Kling v3, Sora 2, Veo 3, Wan 2.6, Seedance Pro, Hailuo 2.3, Runway Gen-3 |
| **Image-to-Video** | 60+ | Kling v2.1 I2V, Veo3 I2V, Runway I2V, Midjourney v7 I2V, Hunyuan I2V, Wan2.2 I2V |

## ğŸ› ï¸ Tech Stack

- **Vite** â€” Build tool & dev server
- **Tailwind CSS v4** â€” Utility-first styling
- **Vanilla JS** â€” No framework, pure DOM manipulation
- **Muapi.ai** â€” AI model API gateway

## ğŸ¤” How is this different from Higgsfield AI?

Higgsfield AI is a proprietary AI video and image generation platform. **Open Higgsfield AI** is a community-driven, open-source alternative that provides similar creative capabilities without the closed ecosystem:

| | Higgsfield AI | Open Higgsfield AI |
| :--- | :--- | :--- |
| **Cost** | Subscription-based | Free (open-source) |
| **Models** | Proprietary | 200+ open & commercial models |
| **Multi-image input** | Limited | Up to 14 images per request |
| **Self-hosting** | No | Yes |
| **Customizable** | No | Fully hackable |
| **Data privacy** | Cloud-based | Your data stays local |
| **Source code** | Closed | MIT licensed |

## ğŸ“„ License

MIT

## ğŸ™ Credits

Built with [Muapi.ai](https://muapi.ai) â€” the unified API for AI image and video generation models.

---
**Deep Dive**: For more details on the "AI Influencer" engine, upcoming "Popcorn" storyboarding features, and the future of this project, read the [full technical overview](https://medium.com/@anilmatcha/building-open-higgsfield-ai-an-open-source-ai-cinema-studio-83c1e0a2a5f1).

---
*Looking for a free Higgsfield AI alternative? Open Higgsfield AI is an open-source AI image and video generation studio and Higgsfield AI replacement that you can self-host, customize, and extend.*
